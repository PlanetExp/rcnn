{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - \n",
      "Loaded dataset  data/grids_9x9_1000.hdf5\n",
      "X.dtype =  float64  X.shape =  (1000, 9, 9)\n",
      "y.dtype =  float64  y.shape =  (1000,)\n",
      "- - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # version 0.12.0rc0\n",
    "import rcnn\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina'  # double res graphs\n",
    "\n",
    "# Load constrained dataset\n",
    "from grid_dataset import load_grid_dataset\n",
    "datasets = load_grid_dataset('data/grids_9x9_1000.hdf5')\n",
    "\n",
    "# Some magic to autoreload external imports\n",
    "# from http://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "training_iters = 2000000\n",
    "batch_size = 128\n",
    "display_step = 50  # Steps after to give some feedback during training\n",
    "validation_step = 1000  # Steps after to run a round of validation to \n",
    "                        # check against overfitting\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1000 # Data input\n",
    "n_classes = 2 # Connected or not connected\n",
    "grid_size = 9\n",
    "height = grid_size\n",
    "width = grid_size\n",
    "depth = 1\n",
    "dropout = 0.5 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width, depth])\n",
    "    y = tf.placeholder(tf.int32, shape=[None])\n",
    "    keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "rcnn = rcnn.Model(X, y, output_size=2, learning_rate=learning_rate, dropout=keep_prob)\n",
    "\n",
    "# Initializing the variables\n",
    "# Note: tensorflow needs to have this initializer after\n",
    "# the model constructor above in order to catch all variables \n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Merge all summaries for tensorboard writer \n",
    "merged = tf.merge_all_summaries()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6400, Minibatch Loss= 240.916046, Training Accuracy= 0.58594\n",
      "Iteration 12800, Minibatch Loss= 50.513233, Training Accuracy= 0.60938\n",
      "Iteration 19200, Minibatch Loss= 14.303511, Training Accuracy= 0.57031\n",
      "Iteration 25600, Minibatch Loss= 1.783519, Training Accuracy= 0.57812\n",
      "Iteration 32000, Minibatch Loss= 3.793252, Training Accuracy= 0.58594\n",
      "Iteration 38400, Minibatch Loss= 4.559061, Training Accuracy= 0.52344\n",
      "Iteration 44800, Minibatch Loss= 1.090672, Training Accuracy= 0.57031\n",
      "Iteration 51200, Minibatch Loss= 1.536652, Training Accuracy= 0.57812\n",
      "Iteration 57600, Minibatch Loss= 1.305753, Training Accuracy= 0.51562\n",
      "Iteration 64000, Minibatch Loss= 1.167704, Training Accuracy= 0.53906\n",
      "Iteration 70400, Minibatch Loss= 1.464793, Training Accuracy= 0.60156\n",
      "Iteration 76800, Minibatch Loss= 1.466116, Training Accuracy= 0.61719\n",
      "Iteration 83200, Minibatch Loss= 0.914302, Training Accuracy= 0.57031\n",
      "Iteration 89600, Minibatch Loss= 0.696417, Training Accuracy= 0.62500\n",
      "Iteration 96000, Minibatch Loss= 0.909568, Training Accuracy= 0.57812\n",
      "Iteration 102400, Minibatch Loss= 1.243876, Training Accuracy= 0.56250\n",
      "Iteration 108800, Minibatch Loss= 0.790958, Training Accuracy= 0.53125\n",
      "Iteration 115200, Minibatch Loss= 0.936431, Training Accuracy= 0.62500\n",
      "Iteration 121600, Minibatch Loss= 0.869259, Training Accuracy= 0.60156\n",
      "Iteration 128000, Minibatch Loss= 0.728329, Training Accuracy= 0.57812\n",
      "Validation Accuracy: 0.5875\n",
      "Iteration 134400, Minibatch Loss= 0.624256, Training Accuracy= 0.66406\n",
      "Iteration 140800, Minibatch Loss= 0.846231, Training Accuracy= 0.56250\n",
      "Iteration 147200, Minibatch Loss= 0.762821, Training Accuracy= 0.55469\n",
      "Iteration 153600, Minibatch Loss= 0.874475, Training Accuracy= 0.53906\n",
      "Iteration 160000, Minibatch Loss= 0.703707, Training Accuracy= 0.62500\n",
      "Iteration 166400, Minibatch Loss= 0.748601, Training Accuracy= 0.60938\n",
      "Iteration 172800, Minibatch Loss= 0.703214, Training Accuracy= 0.58594\n",
      "Iteration 179200, Minibatch Loss= 0.770833, Training Accuracy= 0.58594\n",
      "Iteration 185600, Minibatch Loss= 0.677850, Training Accuracy= 0.63281\n",
      "Iteration 192000, Minibatch Loss= 0.653181, Training Accuracy= 0.64844\n",
      "Iteration 198400, Minibatch Loss= 0.611890, Training Accuracy= 0.68750\n",
      "Iteration 204800, Minibatch Loss= 0.689081, Training Accuracy= 0.66406\n",
      "Iteration 211200, Minibatch Loss= 0.580153, Training Accuracy= 0.67969\n",
      "Iteration 217600, Minibatch Loss= 0.676785, Training Accuracy= 0.63281\n",
      "Iteration 224000, Minibatch Loss= 0.555482, Training Accuracy= 0.67969\n",
      "Iteration 230400, Minibatch Loss= 0.676210, Training Accuracy= 0.59375\n",
      "Iteration 236800, Minibatch Loss= 0.641057, Training Accuracy= 0.66406\n",
      "Iteration 243200, Minibatch Loss= 0.577245, Training Accuracy= 0.67969\n",
      "Iteration 249600, Minibatch Loss= 0.724970, Training Accuracy= 0.62500\n",
      "Iteration 256000, Minibatch Loss= 0.614496, Training Accuracy= 0.65625\n",
      "Validation Accuracy: 0.6\n",
      "Iteration 262400, Minibatch Loss= 0.664696, Training Accuracy= 0.62500\n",
      "Iteration 268800, Minibatch Loss= 0.627110, Training Accuracy= 0.64844\n",
      "Iteration 275200, Minibatch Loss= 0.544749, Training Accuracy= 0.68750\n",
      "Iteration 281600, Minibatch Loss= 0.672896, Training Accuracy= 0.60156\n",
      "Iteration 288000, Minibatch Loss= 0.616158, Training Accuracy= 0.67188\n",
      "Iteration 294400, Minibatch Loss= 0.744622, Training Accuracy= 0.64062\n",
      "Iteration 300800, Minibatch Loss= 0.573719, Training Accuracy= 0.67969\n",
      "Iteration 307200, Minibatch Loss= 0.646854, Training Accuracy= 0.63281\n",
      "Iteration 313600, Minibatch Loss= 0.528353, Training Accuracy= 0.76562\n",
      "Iteration 320000, Minibatch Loss= 0.576951, Training Accuracy= 0.67969\n",
      "Iteration 326400, Minibatch Loss= 0.519963, Training Accuracy= 0.75781\n"
     ]
    }
   ],
   "source": [
    "## Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    \n",
    "    # Profiling tools (only on tensorflow >= 0.12.0rc0)\n",
    "    # Print trainable variable parameter statistics to stdout.\n",
    "    # param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "    #    tf.get_default_graph(),\n",
    "    #    tfprof_options=tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
    "    \n",
    "    # param_stats is tensorflow.tfprof.TFProfNode proto. It organize the statistics\n",
    "    # of each graph node in tree scructure. Let's print the root below.\n",
    "    # print('total_params: %d\\n' % param_stats.total_parameters)\n",
    "    \n",
    "    # Add a summary writer for train steps\n",
    "    train_writer = tf.train.SummaryWriter(\"./logs\", sess.graph)\n",
    "    \n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        \n",
    "        batch_X, batch_y = datasets.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        summary, _ = sess.run([merged, rcnn.train],\n",
    "                              feed_dict={X: batch_X, y: batch_y,\n",
    "                                         keep_prob: dropout})\n",
    "\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Display training steps\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            summary, loss, acc = sess.run([merged, rcnn.loss, rcnn.predict], \n",
    "                                 feed_dict={X: batch_X,\n",
    "                                            y: batch_y,\n",
    "                                            keep_prob: dropout})\n",
    "            \n",
    "            train_writer.add_summary(summary, step)\n",
    "            \n",
    "            print(\"Iteration \" + str(step * batch_size) + \\\n",
    "                  \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        \n",
    "        # Run a round of validation once in a while\n",
    "        if step % validation_step == 0:\n",
    "            print(\"Validation Accuracy:\", \\\n",
    "                  sess.run(rcnn.predict, feed_dict={X: datasets.validation.X[:batch_size],\n",
    "                                                      y: datasets.validation.y[:batch_size],\n",
    "                                                      keep_prob: 1.}))\n",
    "            \n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    train_writer.close()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "          sess.run(rcnn.predict, feed_dict={X: datasets.test.X[:batch_size],\n",
    "                                            y: datasets.test.y[:batch_size],\n",
    "                                            keep_prob: 1.}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
