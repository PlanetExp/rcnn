{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - \n",
      "Loaded dataset  data/grids_9x9_1000.hdf5\n",
      "X.dtype =  float64  X.shape =  (1000, 9, 9)\n",
      "y.dtype =  float64  y.shape =  (1000,)\n",
      "- - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # version 0.12.0rc0\n",
    "import rcnn\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina'  # double res graphs\n",
    "\n",
    "# Load constrained dataset\n",
    "from grid_dataset import load_grid_dataset\n",
    "datasets = load_grid_dataset('data/grids_9x9_1000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 2000000\n",
    "batch_size = 128\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1000 # Data input\n",
    "n_classes = 2 # Connected or not connected\n",
    "grid_size = 9\n",
    "height = grid_size\n",
    "width = grid_size\n",
    "depth = 1\n",
    "dropout = 0.45 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, shape=[None, height, width, depth])\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "rcnn = rcnn.Model(X, y, output_size=2, dropout=keep_prob)\n",
    "\n",
    "# Initializing the variables\n",
    "# Note: tensorflow needs to have this initializer after\n",
    "# the model constructor above in order to catch all variables \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6400, Minibatch Loss= 0.699742, Training Accuracy= 0.41406\n",
      "Iteration 12800, Minibatch Loss= 0.692691, Training Accuracy= 0.51562\n",
      "Iteration 19200, Minibatch Loss= 0.698266, Training Accuracy= 0.46094\n",
      "Iteration 25600, Minibatch Loss= 0.694340, Training Accuracy= 0.50000\n",
      "Iteration 32000, Minibatch Loss= 0.693591, Training Accuracy= 0.50000\n",
      "Iteration 38400, Minibatch Loss= 0.695461, Training Accuracy= 0.45312\n",
      "Iteration 44800, Minibatch Loss= 0.690584, Training Accuracy= 0.53906\n",
      "Iteration 51200, Minibatch Loss= 0.691195, Training Accuracy= 0.53125\n",
      "Iteration 57600, Minibatch Loss= 0.693070, Training Accuracy= 0.50781\n",
      "Iteration 64000, Minibatch Loss= 0.694153, Training Accuracy= 0.48438\n",
      "Iteration 70400, Minibatch Loss= 0.694610, Training Accuracy= 0.46875\n",
      "Iteration 76800, Minibatch Loss= 0.692868, Training Accuracy= 0.52344\n",
      "Iteration 83200, Minibatch Loss= 0.693620, Training Accuracy= 0.48438\n",
      "Iteration 89600, Minibatch Loss= 0.692637, Training Accuracy= 0.52344\n",
      "Iteration 96000, Minibatch Loss= 0.694161, Training Accuracy= 0.48438\n",
      "Iteration 102400, Minibatch Loss= 0.691197, Training Accuracy= 0.53125\n",
      "Iteration 108800, Minibatch Loss= 0.693475, Training Accuracy= 0.46875\n",
      "Iteration 115200, Minibatch Loss= 0.691445, Training Accuracy= 0.53125\n",
      "Iteration 121600, Minibatch Loss= 0.706424, Training Accuracy= 0.46875\n",
      "Iteration 128000, Minibatch Loss= 0.693572, Training Accuracy= 0.50781\n",
      "Iteration 134400, Minibatch Loss= 0.694454, Training Accuracy= 0.46875\n",
      "Iteration 140800, Minibatch Loss= 0.696147, Training Accuracy= 0.49219\n",
      "Iteration 147200, Minibatch Loss= 0.697522, Training Accuracy= 0.47656\n",
      "Iteration 153600, Minibatch Loss= 0.693542, Training Accuracy= 0.47656\n",
      "Iteration 160000, Minibatch Loss= 0.688006, Training Accuracy= 0.56250\n",
      "Iteration 166400, Minibatch Loss= 0.699610, Training Accuracy= 0.46094\n",
      "Iteration 172800, Minibatch Loss= 0.693434, Training Accuracy= 0.37500\n",
      "Iteration 179200, Minibatch Loss= 0.693428, Training Accuracy= 0.45312\n",
      "Iteration 185600, Minibatch Loss= 0.693865, Training Accuracy= 0.41406\n",
      "Iteration 192000, Minibatch Loss= 0.690485, Training Accuracy= 0.53906\n",
      "Iteration 198400, Minibatch Loss= 0.693280, Training Accuracy= 0.49219\n",
      "Iteration 204800, Minibatch Loss= 0.693166, Training Accuracy= 0.49219\n",
      "Iteration 211200, Minibatch Loss= 0.689585, Training Accuracy= 0.57812\n",
      "Iteration 217600, Minibatch Loss= 0.693110, Training Accuracy= 0.53125\n",
      "Iteration 224000, Minibatch Loss= 0.690669, Training Accuracy= 0.53906\n",
      "Iteration 230400, Minibatch Loss= 0.693246, Training Accuracy= 0.50000\n",
      "Iteration 236800, Minibatch Loss= 0.693486, Training Accuracy= 0.50000\n",
      "Iteration 243200, Minibatch Loss= 0.693559, Training Accuracy= 0.46094\n",
      "Iteration 249600, Minibatch Loss= 0.692698, Training Accuracy= 0.51562\n",
      "Iteration 256000, Minibatch Loss= 0.692920, Training Accuracy= 0.57031\n",
      "Iteration 262400, Minibatch Loss= 0.691737, Training Accuracy= 0.53906\n",
      "Iteration 268800, Minibatch Loss= 0.687056, Training Accuracy= 0.57812\n",
      "Iteration 275200, Minibatch Loss= 0.693371, Training Accuracy= 0.49219\n",
      "Iteration 281600, Minibatch Loss= 0.687696, Training Accuracy= 0.55469\n",
      "Iteration 288000, Minibatch Loss= 0.694002, Training Accuracy= 0.48438\n",
      "Iteration 294400, Minibatch Loss= 0.693188, Training Accuracy= 0.50000\n",
      "Iteration 300800, Minibatch Loss= 0.708239, Training Accuracy= 0.44531\n",
      "Iteration 307200, Minibatch Loss= 0.692673, Training Accuracy= 0.51562\n",
      "Iteration 313600, Minibatch Loss= 0.692695, Training Accuracy= 0.51562\n",
      "Iteration 320000, Minibatch Loss= 0.693367, Training Accuracy= 0.50000\n",
      "Iteration 326400, Minibatch Loss= 0.689453, Training Accuracy= 0.57031\n",
      "Iteration 332800, Minibatch Loss= 0.699062, Training Accuracy= 0.46875\n",
      "Iteration 339200, Minibatch Loss= 0.683372, Training Accuracy= 0.58594\n",
      "Iteration 345600, Minibatch Loss= 0.692673, Training Accuracy= 0.52344\n",
      "Iteration 352000, Minibatch Loss= 0.690580, Training Accuracy= 0.53906\n",
      "Iteration 358400, Minibatch Loss= 0.688392, Training Accuracy= 0.55469\n",
      "Iteration 364800, Minibatch Loss= 0.695017, Training Accuracy= 0.48438\n",
      "Iteration 371200, Minibatch Loss= 0.690244, Training Accuracy= 0.55469\n",
      "Iteration 377600, Minibatch Loss= 0.694945, Training Accuracy= 0.50000\n",
      "Iteration 384000, Minibatch Loss= 0.688694, Training Accuracy= 0.56250\n",
      "Iteration 390400, Minibatch Loss= 0.688856, Training Accuracy= 0.55469\n",
      "Iteration 396800, Minibatch Loss= 0.694363, Training Accuracy= 0.49219\n",
      "Iteration 403200, Minibatch Loss= 0.689103, Training Accuracy= 0.57031\n",
      "Iteration 409600, Minibatch Loss= 0.693115, Training Accuracy= 0.50781\n",
      "Iteration 416000, Minibatch Loss= 0.693690, Training Accuracy= 0.50000\n",
      "Iteration 422400, Minibatch Loss= 0.691636, Training Accuracy= 0.57031\n",
      "Iteration 428800, Minibatch Loss= 0.694114, Training Accuracy= 0.50000\n",
      "Iteration 435200, Minibatch Loss= 0.696638, Training Accuracy= 0.43750\n",
      "Iteration 441600, Minibatch Loss= 0.696452, Training Accuracy= 0.46875\n",
      "Iteration 448000, Minibatch Loss= 0.689687, Training Accuracy= 0.57031\n",
      "Iteration 454400, Minibatch Loss= 0.692721, Training Accuracy= 0.52344\n",
      "Iteration 460800, Minibatch Loss= 0.690848, Training Accuracy= 0.53906\n",
      "Iteration 467200, Minibatch Loss= 0.695250, Training Accuracy= 0.46094\n",
      "Iteration 473600, Minibatch Loss= 0.693300, Training Accuracy= 0.50781\n",
      "Iteration 480000, Minibatch Loss= 0.691884, Training Accuracy= 0.53906\n",
      "Iteration 486400, Minibatch Loss= 0.694096, Training Accuracy= 0.46094\n",
      "Iteration 492800, Minibatch Loss= 0.693040, Training Accuracy= 0.50781\n",
      "Iteration 499200, Minibatch Loss= 0.695979, Training Accuracy= 0.50781\n",
      "Iteration 505600, Minibatch Loss= 0.701327, Training Accuracy= 0.45312\n",
      "Iteration 512000, Minibatch Loss= 0.691193, Training Accuracy= 0.53125\n",
      "Iteration 518400, Minibatch Loss= 0.695226, Training Accuracy= 0.50000\n",
      "Iteration 524800, Minibatch Loss= 0.694327, Training Accuracy= 0.39844\n",
      "Iteration 531200, Minibatch Loss= 0.693535, Training Accuracy= 0.40625\n",
      "Iteration 537600, Minibatch Loss= 0.693463, Training Accuracy= 0.47656\n",
      "Iteration 544000, Minibatch Loss= 0.694418, Training Accuracy= 0.42188\n",
      "Iteration 550400, Minibatch Loss= 0.696741, Training Accuracy= 0.42969\n",
      "Iteration 556800, Minibatch Loss= 0.693209, Training Accuracy= 0.42188\n",
      "Iteration 563200, Minibatch Loss= 0.690387, Training Accuracy= 0.54688\n",
      "Iteration 569600, Minibatch Loss= 0.695041, Training Accuracy= 0.50000\n",
      "Iteration 576000, Minibatch Loss= 0.687596, Training Accuracy= 0.55469\n",
      "Iteration 582400, Minibatch Loss= 0.697804, Training Accuracy= 0.46875\n",
      "Iteration 588800, Minibatch Loss= 0.695149, Training Accuracy= 0.45312\n",
      "Iteration 595200, Minibatch Loss= 0.695689, Training Accuracy= 0.45312\n",
      "Iteration 601600, Minibatch Loss= 0.701903, Training Accuracy= 0.44531\n",
      "Iteration 608000, Minibatch Loss= 0.693658, Training Accuracy= 0.50781\n",
      "Iteration 614400, Minibatch Loss= 0.693282, Training Accuracy= 0.50781\n",
      "Iteration 620800, Minibatch Loss= 0.705218, Training Accuracy= 0.46094\n",
      "Iteration 627200, Minibatch Loss= 0.693117, Training Accuracy= 0.50781\n",
      "Iteration 633600, Minibatch Loss= 0.692192, Training Accuracy= 0.52344\n",
      "Iteration 640000, Minibatch Loss= 0.692661, Training Accuracy= 0.51562\n",
      "Iteration 646400, Minibatch Loss= 0.693076, Training Accuracy= 0.50781\n",
      "Iteration 652800, Minibatch Loss= 0.693156, Training Accuracy= 0.49219\n",
      "Iteration 659200, Minibatch Loss= 0.691786, Training Accuracy= 0.57031\n",
      "Iteration 665600, Minibatch Loss= 0.694977, Training Accuracy= 0.50000\n",
      "Iteration 672000, Minibatch Loss= 0.691344, Training Accuracy= 0.53125\n",
      "Iteration 678400, Minibatch Loss= 0.691220, Training Accuracy= 0.53125\n",
      "Iteration 684800, Minibatch Loss= 0.697221, Training Accuracy= 0.45312\n",
      "Iteration 691200, Minibatch Loss= 0.690597, Training Accuracy= 0.58594\n",
      "Iteration 697600, Minibatch Loss= 0.696969, Training Accuracy= 0.47656\n",
      "Iteration 704000, Minibatch Loss= 0.689333, Training Accuracy= 0.55469\n",
      "Iteration 710400, Minibatch Loss= 0.697681, Training Accuracy= 0.48438\n",
      "Iteration 716800, Minibatch Loss= 0.692521, Training Accuracy= 0.57812\n",
      "Iteration 723200, Minibatch Loss= 0.689319, Training Accuracy= 0.54688\n",
      "Iteration 729600, Minibatch Loss= 0.689403, Training Accuracy= 0.60156\n",
      "Iteration 736000, Minibatch Loss= 0.689923, Training Accuracy= 0.55469\n",
      "Iteration 742400, Minibatch Loss= 0.693450, Training Accuracy= 0.48438\n",
      "Iteration 748800, Minibatch Loss= 0.691190, Training Accuracy= 0.58594\n",
      "Iteration 755200, Minibatch Loss= 0.691656, Training Accuracy= 0.53125\n",
      "Iteration 761600, Minibatch Loss= 0.690569, Training Accuracy= 0.53906\n",
      "Iteration 768000, Minibatch Loss= 0.703107, Training Accuracy= 0.46875\n",
      "Iteration 774400, Minibatch Loss= 0.691443, Training Accuracy= 0.53125\n",
      "Iteration 780800, Minibatch Loss= 0.693395, Training Accuracy= 0.49219\n",
      "Iteration 787200, Minibatch Loss= 0.693128, Training Accuracy= 0.53125\n",
      "Iteration 793600, Minibatch Loss= 0.691060, Training Accuracy= 0.57031\n",
      "Iteration 800000, Minibatch Loss= 0.693240, Training Accuracy= 0.50000\n",
      "Iteration 806400, Minibatch Loss= 0.693504, Training Accuracy= 0.49219\n",
      "Iteration 812800, Minibatch Loss= 0.686395, Training Accuracy= 0.57031\n",
      "Iteration 819200, Minibatch Loss= 0.694126, Training Accuracy= 0.46094\n",
      "Iteration 825600, Minibatch Loss= 0.696188, Training Accuracy= 0.48438\n",
      "Iteration 832000, Minibatch Loss= 0.688532, Training Accuracy= 0.55469\n",
      "Iteration 838400, Minibatch Loss= 0.692054, Training Accuracy= 0.52344\n",
      "Iteration 844800, Minibatch Loss= 0.685792, Training Accuracy= 0.58594\n",
      "Iteration 851200, Minibatch Loss= 0.693369, Training Accuracy= 0.43750\n",
      "Iteration 857600, Minibatch Loss= 0.692659, Training Accuracy= 0.51562\n",
      "Iteration 864000, Minibatch Loss= 0.693395, Training Accuracy= 0.50000\n",
      "Iteration 870400, Minibatch Loss= 0.693820, Training Accuracy= 0.45312\n",
      "Iteration 876800, Minibatch Loss= 0.705651, Training Accuracy= 0.45312\n",
      "Iteration 883200, Minibatch Loss= 0.695138, Training Accuracy= 0.46875\n",
      "Iteration 889600, Minibatch Loss= 0.696109, Training Accuracy= 0.50781\n",
      "Iteration 896000, Minibatch Loss= 0.694226, Training Accuracy= 0.46094\n",
      "Iteration 902400, Minibatch Loss= 0.691564, Training Accuracy= 0.53906\n",
      "Iteration 908800, Minibatch Loss= 0.689833, Training Accuracy= 0.56250\n",
      "Iteration 915200, Minibatch Loss= 0.703689, Training Accuracy= 0.46875\n",
      "Iteration 921600, Minibatch Loss= 0.693485, Training Accuracy= 0.43750\n",
      "Iteration 928000, Minibatch Loss= 0.693057, Training Accuracy= 0.50781\n",
      "Iteration 934400, Minibatch Loss= 0.696328, Training Accuracy= 0.50781\n",
      "Iteration 940800, Minibatch Loss= 0.693525, Training Accuracy= 0.50000\n",
      "Iteration 947200, Minibatch Loss= 0.685998, Training Accuracy= 0.57031\n",
      "Iteration 953600, Minibatch Loss= 0.692787, Training Accuracy= 0.51562\n",
      "Iteration 960000, Minibatch Loss= 0.692666, Training Accuracy= 0.51562\n",
      "Iteration 966400, Minibatch Loss= 0.700166, Training Accuracy= 0.48438\n",
      "Iteration 972800, Minibatch Loss= 0.690800, Training Accuracy= 0.55469\n",
      "Iteration 979200, Minibatch Loss= 0.690439, Training Accuracy= 0.56250\n",
      "Iteration 985600, Minibatch Loss= 0.693049, Training Accuracy= 0.50781\n",
      "Iteration 992000, Minibatch Loss= 0.694009, Training Accuracy= 0.50000\n",
      "Iteration 998400, Minibatch Loss= 0.688500, Training Accuracy= 0.58594\n",
      "Iteration 1004800, Minibatch Loss= 0.690266, Training Accuracy= 0.53906\n",
      "Iteration 1011200, Minibatch Loss= 0.694854, Training Accuracy= 0.46094\n",
      "Iteration 1017600, Minibatch Loss= 0.694731, Training Accuracy= 0.46875\n",
      "Iteration 1024000, Minibatch Loss= 0.692166, Training Accuracy= 0.52344\n",
      "Iteration 1030400, Minibatch Loss= 0.695369, Training Accuracy= 0.46875\n",
      "Iteration 1036800, Minibatch Loss= 0.695427, Training Accuracy= 0.45312\n",
      "Iteration 1043200, Minibatch Loss= 0.692119, Training Accuracy= 0.52344\n",
      "Iteration 1049600, Minibatch Loss= 0.689731, Training Accuracy= 0.54688\n",
      "Iteration 1056000, Minibatch Loss= 0.686726, Training Accuracy= 0.59375\n",
      "Iteration 1062400, Minibatch Loss= 0.692655, Training Accuracy= 0.53125\n",
      "Iteration 1068800, Minibatch Loss= 0.697212, Training Accuracy= 0.48438\n",
      "Iteration 1075200, Minibatch Loss= 0.693456, Training Accuracy= 0.49219\n",
      "Iteration 1081600, Minibatch Loss= 0.703458, Training Accuracy= 0.47656\n",
      "Iteration 1088000, Minibatch Loss= 0.689208, Training Accuracy= 0.54688\n",
      "Iteration 1094400, Minibatch Loss= 0.693293, Training Accuracy= 0.50000\n",
      "Iteration 1100800, Minibatch Loss= 0.692442, Training Accuracy= 0.54688\n",
      "Iteration 1107200, Minibatch Loss= 0.695320, Training Accuracy= 0.50781\n",
      "Iteration 1113600, Minibatch Loss= 0.699868, Training Accuracy= 0.45312\n",
      "Iteration 1120000, Minibatch Loss= 0.693098, Training Accuracy= 0.51562\n",
      "Iteration 1126400, Minibatch Loss= 0.702376, Training Accuracy= 0.39844\n",
      "Iteration 1132800, Minibatch Loss= 0.695034, Training Accuracy= 0.49219\n",
      "Iteration 1139200, Minibatch Loss= 0.693692, Training Accuracy= 0.50781\n",
      "Iteration 1145600, Minibatch Loss= 0.689513, Training Accuracy= 0.54688\n",
      "Iteration 1152000, Minibatch Loss= 0.694704, Training Accuracy= 0.49219\n",
      "Iteration 1158400, Minibatch Loss= 0.695509, Training Accuracy= 0.50000\n",
      "Iteration 1164800, Minibatch Loss= 0.701693, Training Accuracy= 0.46094\n",
      "Iteration 1171200, Minibatch Loss= 0.693259, Training Accuracy= 0.49219\n",
      "Iteration 1177600, Minibatch Loss= 0.693838, Training Accuracy= 0.47656\n",
      "Iteration 1184000, Minibatch Loss= 0.699781, Training Accuracy= 0.46094\n",
      "Iteration 1190400, Minibatch Loss= 0.689281, Training Accuracy= 0.57031\n",
      "Iteration 1196800, Minibatch Loss= 0.695076, Training Accuracy= 0.42188\n",
      "Iteration 1203200, Minibatch Loss= 0.694615, Training Accuracy= 0.49219\n",
      "Iteration 1209600, Minibatch Loss= 0.694520, Training Accuracy= 0.46094\n",
      "Iteration 1216000, Minibatch Loss= 0.699725, Training Accuracy= 0.45312\n",
      "Iteration 1222400, Minibatch Loss= 0.694568, Training Accuracy= 0.49219\n",
      "Iteration 1228800, Minibatch Loss= 0.694217, Training Accuracy= 0.49219\n",
      "Iteration 1235200, Minibatch Loss= 0.712508, Training Accuracy= 0.43750\n",
      "Iteration 1241600, Minibatch Loss= 0.692795, Training Accuracy= 0.51562\n",
      "Iteration 1248000, Minibatch Loss= 0.693035, Training Accuracy= 0.50781\n",
      "Iteration 1254400, Minibatch Loss= 0.688616, Training Accuracy= 0.57812\n",
      "Iteration 1260800, Minibatch Loss= 0.697014, Training Accuracy= 0.48438\n",
      "Iteration 1267200, Minibatch Loss= 0.696087, Training Accuracy= 0.48438\n",
      "Iteration 1273600, Minibatch Loss= 0.695600, Training Accuracy= 0.49219\n",
      "Iteration 1280000, Minibatch Loss= 0.700741, Training Accuracy= 0.45312\n",
      "Iteration 1286400, Minibatch Loss= 0.694768, Training Accuracy= 0.47656\n",
      "Iteration 1292800, Minibatch Loss= 0.695754, Training Accuracy= 0.44531\n",
      "Iteration 1299200, Minibatch Loss= 0.690098, Training Accuracy= 0.53906\n",
      "Iteration 1305600, Minibatch Loss= 0.688507, Training Accuracy= 0.57031\n",
      "Iteration 1312000, Minibatch Loss= 0.692929, Training Accuracy= 0.51562\n",
      "Iteration 1318400, Minibatch Loss= 0.693221, Training Accuracy= 0.50000\n",
      "Iteration 1324800, Minibatch Loss= 0.697694, Training Accuracy= 0.45312\n",
      "Iteration 1331200, Minibatch Loss= 0.697193, Training Accuracy= 0.50000\n",
      "Iteration 1337600, Minibatch Loss= 0.693840, Training Accuracy= 0.50781\n",
      "Iteration 1344000, Minibatch Loss= 0.693825, Training Accuracy= 0.49219\n",
      "Iteration 1350400, Minibatch Loss= 0.692789, Training Accuracy= 0.52344\n",
      "Iteration 1356800, Minibatch Loss= 0.690906, Training Accuracy= 0.53906\n",
      "Iteration 1363200, Minibatch Loss= 0.694913, Training Accuracy= 0.49219\n",
      "Iteration 1369600, Minibatch Loss= 0.694861, Training Accuracy= 0.46875\n",
      "Iteration 1376000, Minibatch Loss= 0.688635, Training Accuracy= 0.55469\n",
      "Iteration 1382400, Minibatch Loss= 0.693228, Training Accuracy= 0.47656\n",
      "Iteration 1388800, Minibatch Loss= 0.694926, Training Accuracy= 0.50000\n",
      "Iteration 1395200, Minibatch Loss= 0.693225, Training Accuracy= 0.50781\n",
      "Iteration 1401600, Minibatch Loss= 0.691516, Training Accuracy= 0.53906\n",
      "Iteration 1408000, Minibatch Loss= 0.693143, Training Accuracy= 0.55469\n",
      "Iteration 1414400, Minibatch Loss= 0.693040, Training Accuracy= 0.54688\n",
      "Iteration 1420800, Minibatch Loss= 0.693366, Training Accuracy= 0.47656\n",
      "Iteration 1427200, Minibatch Loss= 0.703400, Training Accuracy= 0.44531\n",
      "Iteration 1433600, Minibatch Loss= 0.691471, Training Accuracy= 0.53125\n",
      "Iteration 1440000, Minibatch Loss= 0.695191, Training Accuracy= 0.42188\n",
      "Iteration 1446400, Minibatch Loss= 0.700150, Training Accuracy= 0.47656\n",
      "Iteration 1452800, Minibatch Loss= 0.696145, Training Accuracy= 0.46875\n",
      "Iteration 1459200, Minibatch Loss= 0.690598, Training Accuracy= 0.54688\n",
      "Iteration 1465600, Minibatch Loss= 0.694799, Training Accuracy= 0.49219\n",
      "Iteration 1472000, Minibatch Loss= 0.691762, Training Accuracy= 0.53906\n",
      "Iteration 1478400, Minibatch Loss= 0.690623, Training Accuracy= 0.53906\n",
      "Iteration 1484800, Minibatch Loss= 0.690598, Training Accuracy= 0.57031\n",
      "Iteration 1491200, Minibatch Loss= 0.696611, Training Accuracy= 0.46875\n",
      "Iteration 1497600, Minibatch Loss= 0.692405, Training Accuracy= 0.53125\n",
      "Iteration 1504000, Minibatch Loss= 0.689036, Training Accuracy= 0.57031\n",
      "Iteration 1510400, Minibatch Loss= 0.696963, Training Accuracy= 0.50000\n",
      "Iteration 1516800, Minibatch Loss= 0.692119, Training Accuracy= 0.60156\n",
      "Iteration 1523200, Minibatch Loss= 0.694346, Training Accuracy= 0.50000\n",
      "Iteration 1529600, Minibatch Loss= 0.693265, Training Accuracy= 0.45312\n",
      "Iteration 1536000, Minibatch Loss= 0.694867, Training Accuracy= 0.46094\n",
      "Iteration 1542400, Minibatch Loss= 0.695654, Training Accuracy= 0.50781\n",
      "Iteration 1548800, Minibatch Loss= 0.699538, Training Accuracy= 0.47656\n",
      "Iteration 1555200, Minibatch Loss= 0.697833, Training Accuracy= 0.47656\n",
      "Iteration 1561600, Minibatch Loss= 0.690237, Training Accuracy= 0.54688\n",
      "Iteration 1568000, Minibatch Loss= 0.695786, Training Accuracy= 0.38281\n",
      "Iteration 1574400, Minibatch Loss= 0.691254, Training Accuracy= 0.53125\n",
      "Iteration 1580800, Minibatch Loss= 0.689243, Training Accuracy= 0.54688\n",
      "Iteration 1587200, Minibatch Loss= 0.693766, Training Accuracy= 0.48438\n",
      "Iteration 1593600, Minibatch Loss= 0.693452, Training Accuracy= 0.50781\n",
      "Iteration 1600000, Minibatch Loss= 0.702905, Training Accuracy= 0.42969\n",
      "Iteration 1606400, Minibatch Loss= 0.693814, Training Accuracy= 0.47656\n",
      "Iteration 1612800, Minibatch Loss= 0.694123, Training Accuracy= 0.50781\n",
      "Iteration 1619200, Minibatch Loss= 0.694610, Training Accuracy= 0.49219\n",
      "Iteration 1625600, Minibatch Loss= 0.689349, Training Accuracy= 0.55469\n",
      "Iteration 1632000, Minibatch Loss= 0.692952, Training Accuracy= 0.51562\n",
      "Iteration 1638400, Minibatch Loss= 0.688693, Training Accuracy= 0.60156\n",
      "Iteration 1644800, Minibatch Loss= 0.693417, Training Accuracy= 0.48438\n",
      "Iteration 1651200, Minibatch Loss= 0.693996, Training Accuracy= 0.44531\n",
      "Iteration 1657600, Minibatch Loss= 0.693470, Training Accuracy= 0.49219\n",
      "Iteration 1664000, Minibatch Loss= 0.687105, Training Accuracy= 0.57031\n",
      "Iteration 1670400, Minibatch Loss= 0.693723, Training Accuracy= 0.50000\n",
      "Iteration 1676800, Minibatch Loss= 0.692405, Training Accuracy= 0.54688\n",
      "Iteration 1683200, Minibatch Loss= 0.692917, Training Accuracy= 0.52344\n",
      "Iteration 1689600, Minibatch Loss= 0.692342, Training Accuracy= 0.57031\n",
      "Iteration 1696000, Minibatch Loss= 0.693243, Training Accuracy= 0.50781\n",
      "Iteration 1702400, Minibatch Loss= 0.692159, Training Accuracy= 0.56250\n",
      "Iteration 1708800, Minibatch Loss= 0.693403, Training Accuracy= 0.50781\n",
      "Iteration 1715200, Minibatch Loss= 0.691827, Training Accuracy= 0.56250\n",
      "Iteration 1721600, Minibatch Loss= 0.691242, Training Accuracy= 0.53125\n",
      "Iteration 1728000, Minibatch Loss= 0.692304, Training Accuracy= 0.52344\n",
      "Iteration 1734400, Minibatch Loss= 0.693029, Training Accuracy= 0.53906\n",
      "Iteration 1740800, Minibatch Loss= 0.693182, Training Accuracy= 0.46094\n",
      "Iteration 1747200, Minibatch Loss= 0.692351, Training Accuracy= 0.53906\n",
      "Iteration 1753600, Minibatch Loss= 0.691739, Training Accuracy= 0.53125\n",
      "Iteration 1760000, Minibatch Loss= 0.694118, Training Accuracy= 0.46875\n",
      "Iteration 1766400, Minibatch Loss= 0.691405, Training Accuracy= 0.53125\n",
      "Iteration 1772800, Minibatch Loss= 0.696338, Training Accuracy= 0.49219\n",
      "Iteration 1779200, Minibatch Loss= 0.692247, Training Accuracy= 0.52344\n",
      "Iteration 1785600, Minibatch Loss= 0.691779, Training Accuracy= 0.53125\n",
      "Iteration 1792000, Minibatch Loss= 0.687837, Training Accuracy= 0.55469\n",
      "Iteration 1798400, Minibatch Loss= 0.690020, Training Accuracy= 0.54688\n",
      "Iteration 1804800, Minibatch Loss= 0.690625, Training Accuracy= 0.53906\n",
      "Iteration 1811200, Minibatch Loss= 0.694522, Training Accuracy= 0.49219\n",
      "Iteration 1817600, Minibatch Loss= 0.692067, Training Accuracy= 0.52344\n",
      "Iteration 1824000, Minibatch Loss= 0.698927, Training Accuracy= 0.43750\n",
      "Iteration 1830400, Minibatch Loss= 0.693016, Training Accuracy= 0.64062\n",
      "Iteration 1836800, Minibatch Loss= 0.688500, Training Accuracy= 0.55469\n",
      "Iteration 1843200, Minibatch Loss= 0.688360, Training Accuracy= 0.55469\n",
      "Iteration 1849600, Minibatch Loss= 0.689214, Training Accuracy= 0.57031\n",
      "Iteration 1856000, Minibatch Loss= 0.710244, Training Accuracy= 0.44531\n",
      "Iteration 1862400, Minibatch Loss= 0.693139, Training Accuracy= 0.50781\n",
      "Iteration 1868800, Minibatch Loss= 0.698381, Training Accuracy= 0.47656\n",
      "Iteration 1875200, Minibatch Loss= 0.701386, Training Accuracy= 0.47656\n",
      "Iteration 1881600, Minibatch Loss= 0.697690, Training Accuracy= 0.45312\n",
      "Iteration 1888000, Minibatch Loss= 0.690486, Training Accuracy= 0.53906\n",
      "Iteration 1894400, Minibatch Loss= 0.691274, Training Accuracy= 0.53125\n",
      "Iteration 1900800, Minibatch Loss= 0.693628, Training Accuracy= 0.48438\n",
      "Iteration 1907200, Minibatch Loss= 0.692738, Training Accuracy= 0.51562\n",
      "Iteration 1913600, Minibatch Loss= 0.693638, Training Accuracy= 0.50781\n",
      "Iteration 1920000, Minibatch Loss= 0.692396, Training Accuracy= 0.52344\n",
      "Iteration 1926400, Minibatch Loss= 0.692254, Training Accuracy= 0.52344\n",
      "Iteration 1932800, Minibatch Loss= 0.689740, Training Accuracy= 0.57031\n",
      "Iteration 1939200, Minibatch Loss= 0.693027, Training Accuracy= 0.50781\n",
      "Iteration 1945600, Minibatch Loss= 0.687233, Training Accuracy= 0.57031\n",
      "Iteration 1952000, Minibatch Loss= 0.695280, Training Accuracy= 0.50000\n",
      "Iteration 1958400, Minibatch Loss= 0.694542, Training Accuracy= 0.50000\n",
      "Iteration 1964800, Minibatch Loss= 0.688884, Training Accuracy= 0.56250\n",
      "Iteration 1971200, Minibatch Loss= 0.691234, Training Accuracy= 0.53125\n",
      "Iteration 1977600, Minibatch Loss= 0.697664, Training Accuracy= 0.50000\n",
      "Iteration 1984000, Minibatch Loss= 0.696177, Training Accuracy= 0.45312\n",
      "Iteration 1990400, Minibatch Loss= 0.693028, Training Accuracy= 0.50781\n",
      "Iteration 1996800, Minibatch Loss= 0.692049, Training Accuracy= 0.52344\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5642f86a4374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     print(\"Testing Accuracy:\",         sess.run(rcnn.evaluate, feed_dict={X: datasets.test.X[:128],\n\u001b[0m\u001b[1;32m     22\u001b[0m                                       \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                       keep_prob: 1.}))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_X, batch_y = datasets.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(rcnn.train, feed_dict={X: batch_X, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([rcnn.loss, rcnn.predict], feed_dict={X: batch_X,\n",
    "                                                              y: batch_y,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iteration \" + str(step * batch_size) + \\\n",
    "                  \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \\\n",
    "                  \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(rcnn.predict, feed_dict={X: datasets.test.X[:128],\n",
    "                                      y: datasets.test.y[:128],\n",
    "                                      keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
